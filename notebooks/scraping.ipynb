{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraper.py & scraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automate the process of extracting reviews from Google Maps, handling dynamic content (such as scrolling and expanding long reviews), and saving both review summaries and detailed reviews in structured CSV files. The approach is modular and can be adapted to different scraping needs. The final version of the code, after refactoring and modularizing it for scalability and maintainability, is located in the scraper.py file inside the src directory. This version includes all necessary improvements, follows best practices for web scraping, and is ready for use. The script efficiently handles dynamic content on Google Maps and saves the extracted data into well-organized CSV files for further analysis. All further updates and enhancements should be implemented in this scraper.py file to maintain consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up WebDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the Chrome WebDriver:\n",
    "\n",
    "- chromedriver_path: Specifies the location of chromedriver (this needs to be correctly configured based on your environment).\n",
    "- chrome_options: Adds custom options (in this case, disabling image loading to improve page load speed).\n",
    "- webdriver.Chrome(): Initializes the Chrome browser with these settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# chromedriver PATH\n",
    "chromedriver_path = '../chromedriver'\n",
    "service = Service(chromedriver_path)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-images\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating to the Target Page and Handling Cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Opens the target Google Maps page using get().\n",
    "- A cookie popup is handled by clicking the 'Accept All' button. If it doesn’t appear, the script moves on without failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"https://www.google.com/maps/place/Cafeter%C3%ADa+HD/@40.4361928,-3.7182915,17.02z/data=!4m8!3m7!1s0xd4228432da1a851:0x3d7986427fb2312e!8m2!3d40.4360712!4d-3.7132937!9m1!1b1!16s%2Fg%2F1tdxx9wf?entry=ttu&g_ep=EgoyMDI0MDkxOC4xIKXMDSoASAFQAw%3D%3D\"\n",
    "driver.get(target)\n",
    "wait = WebDriverWait(driver, 5)\n",
    "\n",
    "try:\n",
    "    accept_button = driver.find_element(By.XPATH, \"//button[@aria-label='Aceptar todo']\")\n",
    "    accept_button.click()\n",
    "    print(\"Se hizo clic en 'Aceptar todo'\")\n",
    "    time.sleep(1)  # Wait\n",
    "except Exception as e:\n",
    "    # If button doesnt appear, continue\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Review Summary (Stars and Review Counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait until the reviews container is fully loaded.\n",
    "- Collect a summary of star ratings and the number of reviews associated with each rating level. The data is stored in two lists (ratings and reviews_counts), which will later be saved into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract starts resume\n",
    "wait = WebDriverWait(driver, 30)\n",
    "reviews_container = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.m6QErb.DxyBCb.kA9KIf.dS8AEf.XiKgde')))\n",
    "\n",
    "raw_html_reviews = driver.find_elements(By.CSS_SELECTOR, 'div.m6QErb.DxyBCb.kA9KIf.dS8AEf.XiKgde')\n",
    "\n",
    "#print(raw_html_reviews[0].text)\n",
    "\n",
    "raw_html_stars_resumme = raw_html_reviews[0].find_elements(By.CSS_SELECTOR, 'tr.BHOKXe')\n",
    "\n",
    "ratings = []\n",
    "reviews_counts = []\n",
    "\n",
    "for star in raw_html_stars_resumme:\n",
    "    rating_text = star.get_attribute('aria-label')\n",
    "    rating_parts = rating_text.split(',')\n",
    "    stars = rating_parts[0].split()[0] \n",
    "    num_reviews = rating_parts[1].strip().split()[0].replace('.', '')\n",
    "    ratings.append(int(stars))\n",
    "    reviews_counts.append(int(num_reviews))\n",
    "\n",
    "stars_resumme = pd.DataFrame({'stars': ratings, 'reviews': reviews_counts})\n",
    "display(stars_resumme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Detailed Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterates over all visible reviews on the page and extracts relevant information, such as the reviewer’s name, rating, review text, and date.\n",
    "- If a review has a \"See More\" button, it clicks to expand the full text.\n",
    "- The script scrolls down to load more reviews and continues until no new reviews are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all visible reviews\n",
    "\n",
    "reviewers = []\n",
    "ratings = []\n",
    "review_texts = []\n",
    "review_dates = []\n",
    "local_guides = []\n",
    "text_backups = []\n",
    "\n",
    "# Init a set for process reviews\n",
    "processed_review_ids = set()\n",
    "\n",
    "SCROLL_PAUSE_TIME = 120\n",
    "\n",
    "last_height = driver.execute_script(\"return arguments[0].scrollHeight\", reviews_container)\n",
    "while True:\n",
    "    # Extract all visible reviews\n",
    "    raw_html_reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf.fontBodyMedium')\n",
    "    \n",
    "    # Extract data for each review\n",
    "    for review in raw_html_reviews:\n",
    "        try:\n",
    "            review_id = review.get_attribute('data-review-id')\n",
    "            \n",
    "            # Verify if review has been processed\n",
    "            if review_id in processed_review_ids:\n",
    "                continue  # Omit processed review\n",
    "            \n",
    "            processed_review_ids.add(review_id)\n",
    "            \n",
    "            try:\n",
    "                more_buttons = review.find_elements(By.CSS_SELECTOR, 'button.w8nwRe')\n",
    "                for button in more_buttons:\n",
    "                    if button.is_displayed():\n",
    "                        button.click()\n",
    "                        time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"No se encontró un botón 'Ver más' en esta reseña: {str(e)}\")\n",
    "\n",
    "            try: reviewer = review.find_element(By.CSS_SELECTOR, 'div.d4r55').text\n",
    "            except: reviewer = ''\n",
    "\n",
    "            try: review_text = review.find_element(By.CSS_SELECTOR, 'span.wiI7pd').text\n",
    "            except: review_text = ''\n",
    "\n",
    "            try: rating = review.find_element(By.CSS_SELECTOR, 'span.kvMYJc').get_attribute('aria-label')\n",
    "            except: rating = ''\n",
    "\n",
    "            try: review_date = review.find_element(By.CSS_SELECTOR, 'span.rsqaWe').text\n",
    "            except: review_date = ''\n",
    "\n",
    "            try: local_guide = review.find_element(By.CLASS_NAME, \"RfnDt\").text\n",
    "            except: local_guide = ''\n",
    "\n",
    "            print(reviewer + ' - ' + rating + ' - ' + review_date + ' - ' + review_text) \n",
    "\n",
    "            reviewers.append(reviewer)\n",
    "            review_texts.append(review_text)\n",
    "            ratings.append(rating)\n",
    "            review_dates.append(review_date)\n",
    "            local_guides.append(local_guide)\n",
    "\n",
    "            text_backups.append(review.text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al extraer una reseña: {str(e)}\")\n",
    "\n",
    "    # Scroll down the page\n",
    "    driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", reviews_container)\n",
    "    time.sleep(10)\n",
    "\n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", reviews_container)\n",
    "    print(new_height)\n",
    "    print(last_height)\n",
    "    # If height doesn't change, wait to load more reviews.\n",
    "    if new_height == last_height:\n",
    "        print('No more reviews detected, forcing additional scroll')\n",
    "        # Wait more reviews to be loaded\n",
    "        time.sleep(SCROLL_PAUSE_TIME) \n",
    "        new_raw_html_reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf.fontBodyMedium')\n",
    "        if len(new_raw_html_reviews) == len(raw_html_reviews): \n",
    "            print('No more reviews loaded, exiting scroll')\n",
    "            break\n",
    "    else:\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Extracted Data to CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the review data is collected, it is organized into a pandas DataFrame and saved as CSV files:\n",
    "-  CSV contains detailed reviews.\n",
    "-  CSV contains the summary of star ratings and the number of reviews for each rating level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_data = pd.DataFrame({\n",
    "    'author': reviewers,\n",
    "    'local_guide_info': local_guides,\n",
    "    'rating': ratings,\n",
    "    'review': review_texts,\n",
    "    'date_text': review_dates,\n",
    "    'text_backup': text_backups\n",
    "})\n",
    "display(collected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'hd.csv'\n",
    "\n",
    "csv_file_path = '../data/raw/collected_reviews_'\n",
    "collected_data.to_csv(csv_file_path + name, index=False)\n",
    "\n",
    "stars_resumme_path = '../data/raw/resumme_'\n",
    "stars_resumme.to_csv(stars_resumme_path + name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
